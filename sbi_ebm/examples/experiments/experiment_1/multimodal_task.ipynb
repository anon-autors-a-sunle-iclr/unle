{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebf1ac-2973-45db-ae86-62c277e800c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbibm.algorithms import snle\n",
    "from sbi_ebm.sbibm.tasks import get_task\n",
    "from sbi_ebm.sbibm.sbibm_eval import snle\n",
    "ret_snle_nsf = snle(task=\"MultiModalLikelihoodTask\", num_samples=0, num_simulations=1000, num_observation=1, num_rounds=1, neural_net=\"nsf\")\n",
    "ret_snle_maf = snle(task=\"MultiModalLikelihoodTask\", num_samples=0, num_simulations=1000, num_observation=1, num_rounds=1, neural_net=\"maf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c462d2-4ddc-4a43-82ce-300b77b5176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_transforms IndependentTransform(ComposeTransform(\n",
      "    \n",
      "), 1)\n",
      "param_transforms IndependentTransform(ComposeTransform(\n",
      "    \n",
      "), 1)\n",
      "Data generation took 0.2019 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98a510039a94a5ea6718ee182f1b4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding good initial position (doubly intractable)\n",
      "finding good initial position\n",
      "finding good initial position\n",
      "good initial position found at:  Traced<ShapedArray(float32[2])>with<BatchTrace(level=1/1)> with\n",
      "  val = Traced<ShapedArray(float32[100,2])>with<DynamicJaxprTrace(level=0/1)>\n",
      "  batch_dim = 0\n",
      "finding good initial position\n",
      "finding good initial position\n",
      "finding good initial position\n"
     ]
    }
   ],
   "source": [
    "from sbi_ebm.sbibm.sbibm_smnle import smnle as run\n",
    "\n",
    "ret = run(\n",
    "    task=\"MultiModalLikelihoodTask\",\n",
    "    num_simulations=100000,\n",
    "    num_rounds=1,\n",
    "    num_observation=1,\n",
    "    # observation=torch.zeros(1, 2),\n",
    "    num_samples=1000,\n",
    "    aux_MCMC_inner_steps_exchange_MCMC=10,\n",
    "    aux_MCMC_proposal_size_exchange_MCMC=0.1,\n",
    "    burnin_exchange_MCMC=10,\n",
    "    bridging_exch_MCMC=0,\n",
    "    propose_new_theta_exchange_MCMC=\"sphere\",\n",
    "    # technique=\"SSM\",\n",
    "    noise_sliced=\"sphere\",\n",
    "    technique=\"SSM\",\n",
    "    epochs=500,\n",
    "    epochs_before_early_stopping=1000,\n",
    "    batch_size=100000,\n",
    "    automatic_transforms_enabled=False,\n",
    "    lr_data=0.005,\n",
    "    SM_lr_theta=0.01,\n",
    "    cuda=True,\n",
    "    no_bn=False,\n",
    "    momentum=0.1,\n",
    "    no_var_red_sliced=True,\n",
    "    no_scheduler=True,\n",
    "    scale_samples=True,\n",
    "    scale_parameters=True,\n",
    "    # theta_vect=theta_vect,\n",
    "    use_jax_mcmc=True,\n",
    "    seed=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f9d6e77-a9f4-48ca-8e53-4088fa558062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using a network of width 50 and depth 4\n",
      "generating data took time:  0:00:00\n",
      "creating dataset with 1000 samples\n",
      "z_scoring theta-part of sampling init dist\n",
      "z_scoring theta-part of inference init dist\n",
      "config.inference.sampling_init_dist=<numpyro.distributions.distribution.TransformedDistribution object at 0x7f1d08429640>\n",
      "training likelihood model...\n",
      "number of datasets:  1\n",
      "first step...\n",
      "....done.\n",
      "iteration 10/200    : 7.705     unnormalized_train_log_l=-3.006     unnormalized_test_log_l=-2.918     train_log_l=-6.792    test_log_l=-6.704    ebm_log_l=-7.442    log_Z=0\n",
      "iteration 20/200    : 0.803     unnormalized_train_log_l=-3.725     unnormalized_test_log_l=-3.657     train_log_l=-5.689    test_log_l=-5.621    ebm_log_l=-5.744    log_Z=0\n",
      "iteration 30/200    : 0.893     unnormalized_train_log_l=-3.443     unnormalized_test_log_l=-3.420     train_log_l=-5.019    test_log_l=-4.996    ebm_log_l=-5.216    log_Z=0\n",
      "iteration 40/200    : 1.471     unnormalized_train_log_l=-3.640     unnormalized_test_log_l=-3.562     train_log_l=-4.210    test_log_l=-4.133    ebm_log_l=-4.139    log_Z=0\n",
      "iteration 50/200    : 2.401     unnormalized_train_log_l=-3.648     unnormalized_test_log_l=-3.663     train_log_l=-3.861    test_log_l=-3.876    ebm_log_l=-3.604    log_Z=0\n",
      "iteration 60/200    : 3.310     unnormalized_train_log_l=-1.754     unnormalized_test_log_l=-1.753     train_log_l=-3.222    test_log_l=-3.221    ebm_log_l=-3.666    log_Z=0\n",
      "iteration 70/200    : 13.748    unnormalized_train_log_l=-0.020     unnormalized_test_log_l=0.132      train_log_l=-2.877    test_log_l=-2.725    ebm_log_l=-2.753    log_Z=0\n",
      "iteration 80/200    : 2.327     unnormalized_train_log_l=0.262      unnormalized_test_log_l=0.350      train_log_l=-2.736    test_log_l=-2.649    ebm_log_l=-2.526    log_Z=0\n",
      "iteration 90/200    : 1.177     unnormalized_train_log_l=0.368      unnormalized_test_log_l=0.422      train_log_l=-2.645    test_log_l=-2.591    ebm_log_l=-2.816    log_Z=0\n",
      "iteration 100/200   : 3.025     unnormalized_train_log_l=-0.187     unnormalized_test_log_l=-0.173     train_log_l=-2.635    test_log_l=-2.620    ebm_log_l=-2.764    log_Z=0\n",
      "iteration 110/200   : 0.949     unnormalized_train_log_l=-0.305     unnormalized_test_log_l=-0.218     train_log_l=-2.691    test_log_l=-2.604    ebm_log_l=-2.779    log_Z=0\n",
      "iteration 120/200   : 2.086     unnormalized_train_log_l=-0.362     unnormalized_test_log_l=-0.294     train_log_l=-2.687    test_log_l=-2.619    ebm_log_l=-2.584    log_Z=0\n",
      "iteration 130/200   : 1.439     unnormalized_train_log_l=-0.293     unnormalized_test_log_l=-0.277     train_log_l=-2.622    test_log_l=-2.606    ebm_log_l=-2.600    log_Z=0\n",
      "iteration 140/200   : 2.570     unnormalized_train_log_l=-0.267     unnormalized_test_log_l=-0.252     train_log_l=-2.599    test_log_l=-2.585    ebm_log_l=-2.575    log_Z=0\n",
      "iteration 150/200   : 1.376     unnormalized_train_log_l=-0.309     unnormalized_test_log_l=-0.222     train_log_l=-2.686    test_log_l=-2.599    ebm_log_l=-2.653    log_Z=0\n",
      "iteration 160/200   : 1.198     unnormalized_train_log_l=-0.440     unnormalized_test_log_l=-0.270     train_log_l=-2.813    test_log_l=-2.643    ebm_log_l=-2.841    log_Z=0\n",
      "iteration 170/200   : 0.618     unnormalized_train_log_l=-0.277     unnormalized_test_log_l=-0.266     train_log_l=-2.595    test_log_l=-2.584    ebm_log_l=-2.693    log_Z=0\n",
      "iteration 180/200   : 0.347     unnormalized_train_log_l=-0.324     unnormalized_test_log_l=-0.325     train_log_l=-2.600    test_log_l=-2.600    ebm_log_l=-2.675    log_Z=0\n",
      "iteration 190/200   : 1.081     unnormalized_train_log_l=-0.361     unnormalized_test_log_l=-0.288     train_log_l=-2.658    test_log_l=-2.585    ebm_log_l=-2.520    log_Z=0\n",
      "iteration 200/200   : 0.295     unnormalized_train_log_l=-0.357     unnormalized_test_log_l=-0.285     train_log_l=-2.654    test_log_l=-2.582    ebm_log_l=-2.731    log_Z=0\n",
      "training ebm took time 0:00:41\n",
      "Best state found after 200 iterations\n",
      "calibration net: None\n",
      "calibration net (init): None\n",
      "sampling from posterior...\n",
      "inference took time:  0:00:10\n",
      "1000\n",
      "sbi_ebm completed in 52.053428411483765 seconds\n"
     ]
    }
   ],
   "source": [
    "from sbi_ebm.sbibm.sbi_ebm import run as run_unle\n",
    "ret_aunle = run_unle(\n",
    "    # \"slcp\", (10000,), 1,\n",
    "    # \"LDCT\", (10000,10000), 1,\n",
    "    # \"slcp\", (2000,2000,2000,2000,2000), 1,\n",
    "    \"MultiModalLikelihoodTask\", (1000,), 1,\n",
    "    num_smc_steps=20,\n",
    "    num_mala_steps=3,\n",
    "    use_warm_start=False,\n",
    "    learning_rate=0.01,\n",
    "    max_iter=200,\n",
    "    weight_decay=0.1,\n",
    "    random_seed=40,\n",
    "    sampler=\"smc\",\n",
    "    num_particles=1000,\n",
    "    batch_size=1000,\n",
    "    restart_every=None,\n",
    "    num_posterior_samples=1000,\n",
    "    use_nuts=False,\n",
    "    init_proposal=\"prior\",\n",
    "    noise_injection_val=0.0005,\n",
    "    proposal=\"prior+noise\",\n",
    "    inference_sampler=\"smc\",\n",
    "    ebm_model_type=\"joint_tilted\",\n",
    "    select_based_on_test_loss=False,\n",
    "    inference_proposal=\"prior\",\n",
    "    use_data_from_past_rounds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a06376c9-f337-4d33-9150-1483d65db5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cloudpickle\n",
    "# with open('ret_multimodal_snle_maf.pkl', 'wb') as f:\n",
    "#     cloudpickle.dump(ret_snle_maf, f)\n",
    "#     \n",
    "# with open('ret_multimodal_snle_nsf.pkl', 'wb') as f:\n",
    "#     cloudpickle.dump(ret_snle_nsf, f)\n",
    "#     \n",
    "# with open('ret_multimodal_smnle.pkl', 'wb') as f:\n",
    "#     cloudpickle.dump(ret, f)\n",
    "#     \n",
    "# with open('ret_multimodal_aunle.pkl', 'wb') as f:\n",
    "#     cloudpickle.dump(ret_aunle, f)\n",
    "#     \n",
    "# with open('ret_multimodal_sunle.pkl', 'wb') as f:\n",
    "#     cloudpickle.dump(ret_sunle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b476950f-8ea6-409b-b55c-d6efb0ae31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from density_utils.plotting import normalize_posterior, normalize_density\n",
    "from sbi_ebm.distributions import maybe_wrap, maybe_wrap_log_l\n",
    "from sbi_ebm.sbibm.tasks import JaxTask, get_task\n",
    "import jax.numpy as jnp\n",
    "smnle_normalized_posterior = normalize_posterior(\n",
    "    # prior=maybe_wrap(ret.train_results.config.task.prior.log_prob),\n",
    "    prior=JaxTask(get_task(\"MultiModalLikelihoodTask\")).get_prior_dist().log_prob,\n",
    "    likelihood=ret.train_results.single_round_results[0].jax_log_likelihood,\n",
    "    x_obs=ret.train_results.config.task.x_obs[0],\n",
    "    # bounds=((-10, 10), (-10, 10)),\n",
    "    bounds=((-8, 8), (-8, 8)),\n",
    "    nbins=101, log_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c7054-d523-4152-99a5-682af535b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import torch\n",
    "from density_utils.plotting import plot_densities\n",
    "from density_utils import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "plt.style.use(\"paper.mplstyle\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "    # \"font.family\": \"Helvetica\"\n",
    "})\n",
    "\n",
    "from sbi_ebm.sbibm.tasks import get_task, JaxTask\n",
    "t = get_task(\"MultiModalLikelihoodTask\")\n",
    "\n",
    "f, axs  = plt.subplots(figsize=(20, 10), ncols=4, nrows=2)\n",
    "\n",
    "\n",
    "_ = axs[0, 0].axis('off')\n",
    "\n",
    "plot_densities({\"sm\": lambda x:  ret.train_results.single_round_results[0].jax_log_likelihood(jnp.zeros((2,)), x)}, bounds=((-5,5), (-5,5)), nbins=100, log_space=True, axs=axs[:, 0], batch_size=10)\n",
    "plot_densities({\"sm\":  smnle_normalized_posterior}, bounds=((-4, 4), (-4,4)), nbins=100, log_space=True, axs=axs[1:, 0], batch_size=10)\n",
    "\n",
    "\n",
    "_ = plotting.plot_density_pytorch(\n",
    "((-4 ,4), (-4, 4)),\n",
    "lambda x: (ret_snle_maf.train_results.posterior.flow.log_prob(theta=torch.zeros((2,)), x=x)[0]).exp(), nbins=100, ax=axs[0, 1]\n",
    ")\n",
    "\n",
    "_ = plotting.plot_density_pytorch(((-4 ,4), (-4, 4)), lambda theta: ret_snle_maf.train_results.posterior.flow.log_prob(theta)[0].exp(), nbins=100, ax=axs[1, 1])\n",
    "\n",
    "plot_densities({\"sm\": lambda x:  ret_aunle.train_results.single_round_results[0].get_posterior(99)._log_likelihood(jnp.zeros((2,)), x)}, bounds=((-4, 4), (-4,4)), nbins=100, log_space=True, axs=axs[:, 2], batch_size=10)\n",
    "plot_densities({\"sm\":  ret_aunle.train_results.single_round_results[0].get_posterior(99).log_prob}, bounds=((-4, 4), (-4,4)), nbins=100, log_space=True, axs=axs[1:, 2], batch_size=10)\n",
    "\n",
    "plot_densities(\n",
    "    {\"sm\":  lambda x: t._jax_log_likelihood(jnp.zeros((2,)), x)}, bounds=((-4, 4), (-4,4)), nbins=100, log_space=True, axs=axs[:, 3], batch_size=10\n",
    ")\n",
    "\n",
    "plot_densities(\n",
    "    {\"sm\":  lambda theta: JaxTask(t).get_prior_dist().log_prob(theta) +  t._jax_log_likelihood(theta, jnp.zeros((2,)))}, bounds=((-4, 4), (-4,4)), nbins=100, log_space=True, axs=axs[1:, 3], batch_size=10\n",
    ")\n",
    "# plot_densities({\"sm\": lambda x:  ret.single_round_results[0].jax_log_likelihood(jnp.zeros((2,)), x)}, bounds=((-4,4), (-4,4)), nbins=40, log_space=True, axs=axs)\n",
    "\n",
    "for rax in axs:\n",
    "    for ax in rax:\n",
    "        ax.axis('off')\n",
    "\n",
    "axs[0, 0].text(x=0.5, y=1.2, size=24, horizontalalignment='center', s=\"SMNLE\", transform=axs[0, 0].transAxes)\n",
    "axs[0, 1].text(x=0.5, y=1.2, size=24, horizontalalignment='center', s=\"NLE\", transform=axs[0, 1].transAxes)\n",
    "axs[0, 2].text(x=0.5, y=1.2, size=24, horizontalalignment='center', s=\"AUNLE (Ours)\", transform=axs[0, 2].transAxes, fontweight=\"bold\")\n",
    "axs[0, 3].text(x=0.5, y=1.2, size=24, horizontalalignment='center', s=\"Ground Truth\", transform=axs[0, 3].transAxes)\n",
    "\n",
    "axs[0, 0].text(x=-0.1, y=0.5, size=24, horizontalalignment='right', s=\"Likelihood\", transform=axs[0, 0].transAxes)\n",
    "axs[1, 0].text(x=-0.1, y=0.5, size=24, horizontalalignment='right', s=\"Posterior\", transform=axs[1, 0].transAxes)\n",
    "\n",
    "# f.savefig('multimodal_posterior_fig.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unle",
   "language": "python",
   "name": "unle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
